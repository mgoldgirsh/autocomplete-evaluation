{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries to perform word2vec encodings\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Phrases\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths: \n",
      "train 5121 \n",
      "validation 2169 \n",
      "test 2227\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets \n",
    "# Taken From: \n",
    "# https://sites.google.com/site/daehpark/Resources/data-set-for-query-auto-completion-sigir-2017 \n",
    "\n",
    "# @inproceedings{park2017neural,   \n",
    "#                title={A neural language model for query auto-completion},\n",
    "#                author={Park, Dae Hoon and Chiba, Rikio},\n",
    "#                booktitle={Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},\n",
    "#                pages={1189--1192},\n",
    "#                year={2017},\n",
    "#                organization={ACM} }\n",
    "\n",
    "def load_dataset(f: str, sep: str='\\t') -> dict: \n",
    "    \"\"\"Loads the dataset from a file into memory.\n",
    "\n",
    "    Args:\n",
    "        f (str): the file to load the dataset from\n",
    "        sep (str, optional): the seperator to use to delimit the file. Defaults to '\\t'.\n",
    "\n",
    "    Returns:\n",
    "        dict: a dictionary of the QAC data loaded into the memory.\n",
    "    \"\"\"\n",
    "    data = { }  # dictionary with final query : prefixes\n",
    "    with open(f, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            item = line.split(sep)\n",
    "            partial, full = item[0].strip(), item[1].strip()\n",
    "            if full in data: \n",
    "                data[full].append(partial)\n",
    "            else:\n",
    "                data[full] = [partial]\n",
    "    return data\n",
    "\n",
    "qac_train = load_dataset('qac_data/qac_training.tsv')\n",
    "qac_val = load_dataset('qac_data/qac_validation.tsv')\n",
    "qac_test = load_dataset('qac_data/qac_test.tsv')\n",
    "\n",
    "print('Lengths:','\\ntrain',len(qac_train), '\\nvalidation',len(qac_val), '\\ntest', len(qac_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9515382, 9698800)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "w2v_model_size100 = Word2Vec(vector_size=100, min_count=1, workers=cores-1)  # create a word2vec model with vector size 100\n",
    "\n",
    "vocab = [prefixes + query.strip().split(' ') + [query] for query, prefixes in qac_train.items()]\n",
    "\n",
    "w2v_model_size100.build_vocab(vocab)  # build the vocab for the number of sentences\n",
    "w2v_model_size100.train(vocab, total_examples=len(vocab), epochs=100, report_delay=1)  # train the word2vec model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ritz hotel', 0.9652626),\n",
       " ('straithaven hotel', 0.9553758),\n",
       " ('iriquois hotel', 0.95321584),\n",
       " ('hilton hotel kingston jamaica', 0.94994247),\n",
       " ('hotel 71 chicago il', 0.9481164)]"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now using the word2vec model we can predict autocompletion of words in the vocab\n",
    "def predict(partial_q: str, model, context:str=None, k:int=5) -> list:\n",
    "    results = []\n",
    "    \n",
    "    for sentence in qac_train:  \n",
    "        # check the cosine similarity of the query and output\n",
    "        contexted_q = partial_q\n",
    "        if context is not None:\n",
    "            # try to see if the contexted q is in the vocab\n",
    "            try: \n",
    "                model.wv[context + partial_q]\n",
    "                contexted_q = context + partial_q\n",
    "            except: \n",
    "                contexted_q = partial_q\n",
    "                \n",
    "            try: \n",
    "                model.wv[partial_q + context]\n",
    "                contexted_q = partial_q + context\n",
    "            except: \n",
    "                contexted_q = partial_q\n",
    "            \n",
    "        # then check similarity\n",
    "        sim = model.wv.similarity(sentence, contexted_q)\n",
    "        results.append((sentence, sim))\n",
    "\n",
    "    if k is None:\n",
    "        output = sorted(results, key=lambda item: item[1], reverse=True)\n",
    "    else:\n",
    "        output = sorted(results, key=lambda item: item[1], reverse=True)[:k]\n",
    "        \n",
    "    return output\n",
    "\n",
    "predict('hotel', w2v_model_size100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
